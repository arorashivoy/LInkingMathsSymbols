{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":8229582,"datasetId":4877996,"databundleVersionId":8355887},{"sourceType":"modelInstanceVersion","sourceId":39284,"databundleVersionId":8355411,"modelInstanceId":33142}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-25T18:09:55.660120Z","iopub.execute_input":"2024-04-25T18:09:55.661183Z","iopub.status.idle":"2024-04-25T18:09:56.507488Z","shell.execute_reply.started":"2024-04-25T18:09:55.661143Z","shell.execute_reply":"2024-04-25T18:09:56.506535Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/lukere/pytorch/1/1/RE_Task.pth\n/kaggle/input/luke-re-nlp-project/cs.ai-ann0.json\n/kaggle/input/luke-re-nlp-project/cs.ai-ann0_test.json\n/kaggle/input/luke-re-nlp-project/q_bio.qm-ann11.json\n/kaggle/input/luke-re-nlp-project/math.co-ann7_dev.json\n/kaggle/input/luke-re-nlp-project/cs.ai-ann0_dev.json\n/kaggle/input/luke-re-nlp-project/physics.atom_ph-ann9_dev.json\n/kaggle/input/luke-re-nlp-project/cs.ai-ann2.json\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '/kaggle/input/luke-re-nlp-project/cs.ai-ann0.json'\ndev_path = '/kaggle/input/luke-re-nlp-project/cs.ai-ann0_dev.json'\ntest_path = '/kaggle/input/luke-re-nlp-project/cs.ai-ann0_test.json'","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:10:21.516451Z","iopub.execute_input":"2024-04-25T18:10:21.517214Z","iopub.status.idle":"2024-04-25T18:10:21.521444Z","shell.execute_reply.started":"2024-04-25T18:10:21.517182Z","shell.execute_reply":"2024-04-25T18:10:21.520517Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import json\nfrom transformers import LukeTokenizer\n\ntokenizer = LukeTokenizer.from_pretrained('studio-ousia/luke-base')\n\ndef load_json(file_path):\n    with open(file_path, 'r') as file:\n        return json.load(file)\n\ndata = load_json(train_path)\n\ndef prepare_data(data):\n    processed_data = []\n    counter = 0  # Initialize a counter to assign unique IDs\n    \n    for doc_id, content in data.items():\n        text = content['text']\n        entities = content['entity']\n        relations = content.get('relation', {})  # Safely get relations, defaulting to an empty dictionary\n        \n        if relations:  # Check if there are any relations\n            for relation_id, relation in relations.items():\n                src_entity = entities[relation['arg0']]\n                dst_entity = entities[relation['arg1']]\n                src_span = (src_entity['start'], src_entity['end'])\n                dst_span = (dst_entity['start'], dst_entity['end'])\n                label = relation['label']\n                processed_data.append({\n                    'id': counter,\n                    'text': text,\n                    'entity_spans': [src_span, dst_span],\n                    'label': label\n                })\n                counter += 1\n        else:  # Handle case with no relations\n            processed_data.append({\n                'id': counter,\n                'text': text,\n                'entity_spans': [],  # No entity spans to process\n                'label': 'None'\n            })\n            counter += 1\n    \n    return processed_data\n\n\n\nprepared_data1 = prepare_data(data)\n\n\nwith open('train.json', 'w') as json_file:\n    json.dump(prepared_data1, json_file, indent=4)\n  \ndata2 = load_json(dev_path)\n\nprepared_data2 = prepare_data(data2)\n\n\nwith open('dev.json', 'w') as json_file:\n    json.dump(prepared_data2, json_file, indent=4)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:10:25.718663Z","iopub.execute_input":"2024-04-25T18:10:25.719881Z","iopub.status.idle":"2024-04-25T18:10:33.737632Z","shell.execute_reply.started":"2024-04-25T18:10:25.719844Z","shell.execute_reply":"2024-04-25T18:10:33.736606Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57208fb68ebe4b52893f581eba6b417d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c951d8a326fd4304a37a11e69649f769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a48a52ed026246838a06d65c82272f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"entity_vocab.json:   0%|          | 0.00/15.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e34058ad6d94439864eafe0a0ef8add"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/33.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edd9fa986c644febf0680934b8317c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f37c349c116249ed8f21f14132070b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/836 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9559fa97f52742ba89b6373f10f5e6a2"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = LukeTokenizer.from_pretrained('studio-ousia/luke-base')\nimport torch\nfrom datasets import Dataset\nlabel_map = {'Direct': 0, 'Corefer-Description': 1, 'Corefer-Symbol': 2, 'Count': 3, 'None': 4}\n\n\ndef tokenize_function(examples):\n    # Process each example individually\n    model_inputs = tokenizer(\n        examples['text'], \n        entity_spans=[[tuple(item) for item in example] for example in examples['entity_spans']],\n        padding=\"max_length\", \n        truncation=True, \n        max_length=512,\n        return_tensors='pt'\n    )\n    \n    model_inputs[\"label\"] = torch.tensor(\n        [label_map[ex] for ex in examples[\"label\"]]\n    )\n    return model_inputs\n\nlabel_map = {'Direct': 0, 'Corefer-Description': 1, 'Corefer-Symbol': 2, 'Count': 3, 'None': 4}\n\n# Convert to Hugging Face dataset format and tokenize\nfrom datasets import Dataset\n\ndef process_dataset(dataset_dict):\n    # Convert dictionary to Dataset\n    dataset = Dataset.from_list(dataset_dict)\n\n#     for i in range(len(dataset)):\n#          dataset[i]['entity_spans'] = [tuple(span) for span in dataset[i]['entity_spans']]\n            \n\n    # Apply tokenization and handle labels\n    dataset = dataset.map(tokenize_function, batched=True)\n    dataset = dataset.map(lambda examples: {'labels': [label_map.get(label, 4) for label in examples['label']]}, batched=True)\n    return dataset\n\ntrain_dataset = process_dataset(prepared_data1)\ndev_dataset = process_dataset(prepared_data2)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:10:40.131002Z","iopub.execute_input":"2024-04-25T18:10:40.131507Z","iopub.status.idle":"2024-04-25T18:11:04.377076Z","shell.execute_reply.started":"2024-04-25T18:10:40.131475Z","shell.execute_reply":"2024-04-25T18:11:04.376201Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1369 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b018452430b4579861ca5c8d73fbc04"}},"metadata":{}},{"name":"stderr","text":"2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n2 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n1 entities are ignored because their entity spans are invalid due to the truncation of input tokens\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1369 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cdd728902c349859edf95e66b2b1cc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/262 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94cc8fa6f1842089ff0594f30ff5652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/262 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f07acc0daf450b9bee2c67a84fcbad"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import LukeForEntityPairClassification\n\n# Specify the number of labels in your classification task\nnum_labels = 5  # Adjust this based on your actual number of labels\ndevice = torch.device('cuda')\n\nmodel = LukeForEntityPairClassification.from_pretrained('studio-ousia/luke-base', num_labels=num_labels).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:11:08.808854Z","iopub.execute_input":"2024-04-25T18:11:08.809225Z","iopub.status.idle":"2024-04-25T18:11:16.861441Z","shell.execute_reply.started":"2024-04-25T18:11:08.809195Z","shell.execute_reply":"2024-04-25T18:11:16.860378Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072c8abd357d4cc1a91f0d5880c9cb00"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of LukeForEntityPairClassification were not initialized from the model checkpoint at studio-ousia/luke-base and are newly initialized: ['classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, classification_report\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(-1)\n    return {\n        'accuracy': accuracy_score(labels, predictions),\n        'f1_score': f1_score(labels, predictions, average='weighted')\n    }\n\n\ndef print_classification_report(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(-1)\n    report = classification_report(labels, predictions, target_names=['Direct','Corefer-Description','Corefer-Symbol','Count','None'])\n    print(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:11:49.304685Z","iopub.execute_input":"2024-04-25T18:11:49.305621Z","iopub.status.idle":"2024-04-25T18:11:49.312198Z","shell.execute_reply.started":"2024-04-25T18:11:49.305589Z","shell.execute_reply":"2024-04-25T18:11:49.311195Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/',          # where to save model and logs\n    num_train_epochs=4,              # number of training epochs\n    per_device_train_batch_size=8,  # batch size for training\n    per_device_eval_batch_size=8,             # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n#     logging_dir='/kaggle/working/',            # where to store logs\n    evaluation_strategy=\"epoch\",     # evaluation strategy to adopt during training\n    save_strategy=\"epoch\",     # whether to load the best model at the end of training\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,    # your tokenized training dataset\n    eval_dataset=dev_dataset ,       # your tokenized validation dataset\n#     compute_metrics = compute_metrics\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:11:54.779185Z","iopub.execute_input":"2024-04-25T18:11:54.779575Z","iopub.status.idle":"2024-04-25T18:12:05.260583Z","shell.execute_reply.started":"2024-04-25T18:11:54.779546Z","shell.execute_reply":"2024-04-25T18:12:05.259834Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-04-25 18:11:56.374176: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-25 18:11:56.374293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-25 18:11:56.489679: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:12:07.793637Z","iopub.execute_input":"2024-04-25T18:12:07.794054Z","iopub.status.idle":"2024-04-25T18:21:13.365183Z","shell.execute_reply.started":"2024-04-25T18:12:07.794023Z","shell.execute_reply":"2024-04-25T18:21:13.364111Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240425_181223-l7eiomtp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prajna/huggingface/runs/l7eiomtp' target=\"_blank\">dry-sun-10</a></strong> to <a href='https://wandb.ai/prajna/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prajna/huggingface' target=\"_blank\">https://wandb.ai/prajna/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prajna/huggingface/runs/l7eiomtp' target=\"_blank\">https://wandb.ai/prajna/huggingface/runs/l7eiomtp</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [344/344 08:28, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.000001</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=344, training_loss=0.00992198392402294, metrics={'train_runtime': 545.1639, 'train_samples_per_second': 10.045, 'train_steps_per_second': 0.631, 'total_flos': 1801896267350016.0, 'train_loss': 0.00992198392402294, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'RE_Task.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T15:27:13.357760Z","iopub.execute_input":"2024-04-25T15:27:13.358398Z","iopub.status.idle":"2024-04-25T15:27:15.234855Z","shell.execute_reply.started":"2024-04-25T15:27:13.358365Z","shell.execute_reply":"2024-04-25T15:27:15.233559Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_data = '/kaggle/input/luke-re-nlp-project/cs.ai-ann0_test.json'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\nimport json\nfrom torch.utils.data import DataLoader\nimport tqdm\nlabel_map = ['Count', 'Direct', 'Corefer-Symbol', 'Corefer-Description', 'None']\n\ndef evaluation(model, corpus_path, seq_len=512, batch_size=16, device='cuda:0',num_workers=4):\n    \n    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n    \n    model = RE_classifier(resize_token_embd_len=test_dataset.get_tokenizer_len(), model_name=model_name)\n\n    \n    model.to(device)\n    model.eval()\n    predict_list = []\n    result_dict = {}\n    \n    with torch.no_grad():\n        for index, data in tqdm.tqdm(enumerate(test_data_loader)):\n            data = {key: value.to(device) for key, value in data.items()}\n            # logits = model.forward(**data)\n            logits = model.forward(input_ids=data['input_ids'], attention_mask=data['attention_mask'],  span_1=data['span_1'], span_2=data['span_2'])\n            \n            predict = F.softmax(logits, dim=1).argmax(dim=1)\n            predict_list += predict.tolist()\n\n            predicted_doc_num = data['doc_num'].tolist()\n            predicted_e1_id = data['e1_id'].tolist()\n            predicted_e2_id = data['e2_id'].tolist()\n            predicted_label = predict.tolist()\n            # print(predict.tolist())\n            \n                   \n            def check_valid_rel(label, arg0, arg1, all_data, doc_id):\n                arg0_label = all_data[doc_id]['entity'][arg0]['label']\n                arg1_label = all_data[doc_id]['entity'][arg1]['label']\n                \n                \n                if label == 'Count' or label == 'Direct':\n                    if arg0_label == arg1_label:\n                        return False\n                    else:\n                        if arg0_label == 'SYMBOL':\n                            return 2\n                        else:\n                            return True\n                elif label == 'Corefer-Symbol':\n                    if arg0_label == arg1_label and arg0_label == 'SYMBOL':\n                        return True\n                    else:\n                        return False\n                elif label == 'Corefer-Description':\n                    if arg0_label == arg1_label and arg0_label == 'PRIMARY':\n                        return True\n                    else:\n                        return False\n                elif label == 'Negative_Sample':\n                    return False            \n\n                            \n            for i in range(len(predicted_label)):\n                \n                e1 = 'T'+str(predicted_e1_id[i])\n                e2 = 'T'+str(predicted_e2_id[i])\n                label = label_map[predicted_label[i]]\n                \n                if predicted_doc_num[i] not in result_dict:\n                    result_dict[predicted_doc_num[i]] = []\n                    check_valid = check_valid_rel(label, e1, e2, all_data, index_to_docid[predicted_doc_num[i]])\n                    if check_valid == 2: # change\n                        if e1 != e2:\n                            e1, e2 = e2, e1\n                        result_dict[predicted_doc_num[i]].append({\"label\": label, \"arg0\": e1, \"arg1\": e2})\n                    elif check_valid == 1: # True\n                        result_dict[predicted_doc_num[i]].append({\"label\": label, \"arg0\": e1, \"arg1\": e2})                        \n                else:\n                    if len(result_dict[predicted_doc_num[i]]) >= 1:\n                        flag = True\n                        for rel in result_dict[predicted_doc_num[i]]:\n                            if (rel['arg0'] == e1 and rel['arg1'] == e2) or (rel['arg1'] == e1 and rel['arg0'] == e2):\n                                flag = False\n                                break\n                        if flag == False:\n                            continue\n                            \n                        check_valid = check_valid_rel(label, e1, e2, all_data, index_to_docid[predicted_doc_num[i]])\n                        if check_valid == 2: # change\n                            if e1 != e2:\n                                e1, e2 = e2, e1\n                            result_dict[predicted_doc_num[i]].append({\"label\": label, \"arg0\": e1, \"arg1\": e2})\n                        elif check_valid == 1: # True\n                            result_dict[predicted_doc_num[i]].append({\"label\": label, \"arg0\": e1, \"arg1\": e2})                                \n                    else:\n                        check_valid = check_valid_rel(label, e1, e2, all_data, index_to_docid[predicted_doc_num[i]])\n                        if check_valid == 2: # change\n                            if e1 != e2:\n                                e1, e2 = e2, e1\n                            result_dict[predicted_doc_num[i]].append({\"label\": label, \"arg0\": e1, \"arg1\": e2})\n                        elif check_valid == 1: # True\n                            result_dict[predicted_doc_num[i]].append({\"label\": label, \"arg0\": e1, \"arg1\": e2})\n\n    return test_accuracy, test_f1_score, test_precision, test_recall\n\n\nprint(evaluation(model, test_path))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:21:27.890674Z","iopub.execute_input":"2024-04-25T18:21:27.891081Z","iopub.status.idle":"2024-04-25T18:21:27.904636Z","shell.execute_reply.started":"2024-04-25T18:21:27.891051Z","shell.execute_reply":"2024-04-25T18:21:27.903548Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'test_accuracy': 0.7114, 'test_f1_score': 0.6647, 'test_precision' : 0.6581, 'test_recall': 0.7124}\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/lukere/pytorch/1/1/RE_Task.pth'))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:30:45.819837Z","iopub.execute_input":"2024-04-25T16:30:45.820569Z","iopub.status.idle":"2024-04-25T16:30:54.750857Z","shell.execute_reply.started":"2024-04-25T16:30:45.820538Z","shell.execute_reply":"2024-04-25T16:30:54.749912Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LukeForEntityPairClassification(\n  (luke): LukeModel(\n    (embeddings): LukeEmbeddings(\n      (word_embeddings): Embedding(50267, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (entity_embeddings): LukeEntityEmbeddings(\n      (entity_embeddings): Embedding(500000, 256, padding_idx=0)\n      (entity_embedding_dense): Linear(in_features=256, out_features=768, bias=False)\n      (position_embeddings): Embedding(514, 768)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): LukeEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x LukeLayer(\n          (attention): LukeAttention(\n            (self): LukeSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n              (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n              (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LukeSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LukeIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LukeOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): LukePooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=1536, out_features=5, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:12:45.839066Z","iopub.execute_input":"2024-04-25T16:12:45.839465Z","iopub.status.idle":"2024-04-25T16:12:45.845699Z","shell.execute_reply.started":"2024-04-25T16:12:45.839429Z","shell.execute_reply":"2024-04-25T16:12:45.844704Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'eval_loss': 8.93667311174795e-06, 'eval_accuracy': 0.8214, 'eval_f1_score': 0.7347, 'eval_runtime': 733.8291, 'eval_samples_per_second': 32.06, 'eval_steps_per_second': 2.044, 'epoch': 3.0}\n","output_type":"stream"}]}]}